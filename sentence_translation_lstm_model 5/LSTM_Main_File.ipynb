{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import json\n",
        "import numpy as np\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "jcweI-2OVApD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "S70fKeuhVTTi",
        "outputId": "6e2c75af-5599-4c33-a03d-5d1d011797f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using the stored files and getting the data from them\n",
        "\n",
        "en_train_df = pd.read_csv('/content/drive/MyDrive/datasets/en_train2.csv')\n",
        "hn_train_df = pd.read_csv('/content/drive/MyDrive/datasets/hn_train2.csv')\n",
        "en_val_df = pd.read_csv('/content/drive/MyDrive/datasets/en_val2.csv')\n",
        "\n",
        "en_train = [[v for v in row if not pd.isna(v)] for row in en_train_df.values.tolist()]\n",
        "hn_train = [[v for v in row if not pd.isna(v)] for row in hn_train_df.values.tolist()]\n",
        "en_val = [[v for v in row if not pd.isna(v)] for row in en_val_df.values.tolist()]"
      ],
      "metadata": {
        "id": "PzL7n0B7hFaL",
        "outputId": "25dea1f1-b108-4c63-83e8-1c8888cc8767",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-081fd30bb4b2>:1: DtypeWarning: Columns (73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  en_train_df = pd.read_csv('/content/drive/MyDrive/datasets/en_train2.csv')\n",
            "<ipython-input-20-081fd30bb4b2>:2: DtypeWarning: Columns (57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  hn_train_df = pd.read_csv('/content/drive/MyDrive/datasets/hn_train2.csv')\n",
            "<ipython-input-20-081fd30bb4b2>:3: DtypeWarning: Columns (59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174) have mixed types. Specify dtype option on import or set low_memory=False.\n",
            "  en_val_df = pd.read_csv('/content/drive/MyDrive/datasets/en_val2.csv')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(en_train))\n",
        "print(len(hn_train))\n",
        "print(len(en_val))"
      ],
      "metadata": {
        "id": "ni7ulU_ah3T0",
        "outputId": "1171b897-dbd0-444e-b3fe-02f79cffcf6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68849\n",
            "68849\n",
            "9836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(en_train[0])\n",
        "print(hn_train[0])"
      ],
      "metadata": {
        "id": "QtQbbEsih80C",
        "outputId": "196f883c-11f3-45d0-bc4d-c5bba32b877e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['do', 'not', 'forget', 'to', 'visit', 'the', 'point', 'where', 'the', 'narmada', 'flowing', 'through', 'the', 'marble', 'rocks', 'interchanges', 'its', 'calmness', 'and', 'serenity', 'into', 'insouciance']\n",
            "['এই', 'জায়গাগুলো', 'দেখতে', 'ভুলো', 'না', 'যেখানে', 'নর্মদা', 'নদী', 'মার্বেল', 'পাথরের', 'পাহাড়ের', 'মধ্য', 'দিয়ে', 'প্রবাহিত', 'হচ্ছে', 'এবং', 'নিজের', 'শান্তি', 'ও', 'সৌন্দর্যকে', 'অনাসক্তিতে', 'পরিণত', 'করছে', '।']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "en_dict = {}\n",
        "hn_dict = {}\n",
        "\n",
        "# Creating the dictionaries of the training datasets\n",
        "\n",
        "def add(dict, word):\n",
        "  if word not in dict:\n",
        "    dict[word] = len(dict)\n",
        "  return\n",
        "\n",
        "extras = ['<EOS>', '<SOS>', '<PAD>']\n",
        "\n",
        "for word in extras:\n",
        "  add(en_dict, word)\n",
        "  add(hn_dict, word)\n",
        "\n",
        "for sentence in en_train:\n",
        "  for word in sentence:\n",
        "    add(en_dict, word)\n",
        "\n",
        "for sentence in hn_train:\n",
        "  for word in sentence:\n",
        "    add(hn_dict, word)\n",
        "\n",
        "# for sentence in en_val:\n",
        "#   for word in sentence:\n",
        "#     add(en_dict, word)"
      ],
      "metadata": {
        "id": "nrxDJsoKiCUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in en_val:\n",
        "  for word in sentence:\n",
        "    add(en_dict, word)"
      ],
      "metadata": {
        "id": "KWPl8UsYUmR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(en_dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bq8_-NptUnoV",
        "outputId": "fd6807aa-96bc-473e-c8f7-0cc5d6c39580"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 27"
      ],
      "metadata": {
        "id": "_YFvWhBiiGLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# appending SOS, EOS, and PAD to equal length\n",
        "def append(sentence):\n",
        "  sentence.insert(0, '<SOS>')\n",
        "  while (len(sentence) < MAX_LEN - 1):\n",
        "    sentence.append('<PAD>')\n",
        "  while (len(sentence) > MAX_LEN - 1):\n",
        "    sentence.pop()\n",
        "  sentence.append('<EOS>')\n",
        "  return sentence"
      ],
      "metadata": {
        "id": "msPVAbdpiM6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding sentences into sequences\n",
        "def encode(dict, sentence):\n",
        "  sentence = append(sentence)\n",
        "  res = []\n",
        "  for word in sentence:\n",
        "    res.append(dict[word])\n",
        "  return res"
      ],
      "metadata": {
        "id": "j9M1tHPsiPKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentences(dict, sentences):\n",
        "  res = []\n",
        "  for sentence in sentences:\n",
        "    res.append(encode(dict, sentence))\n",
        "  return res"
      ],
      "metadata": {
        "id": "eTBSP7RtiRVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "en_tokentrain = encode_sentences(en_dict, en_train)\n",
        "hn_tokentrain = encode_sentences(hn_dict, hn_train)\n",
        "en_tokenval = encode_sentences(en_dict, en_val)"
      ],
      "metadata": {
        "id": "Lbyyru4FiUla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(en_tokentrain[0])\n",
        "print(hn_tokentrain[0])"
      ],
      "metadata": {
        "id": "8TgMHjwiiWC5",
        "outputId": "80d3cd31-3c9c-4488-a419-fda55b0553ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 3, 4, 5, 6, 7, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0]\n",
            "[1, 3, 4, 5, 6, 7, 8, 9, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8VEsrteKnsM8",
        "outputId": "07ee3832-7c60-4245-de32-bf76390b972e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-23 08:42:30--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2024-11-23 08:42:30--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2024-11-23 08:42:31--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.86MB/s    in 2m 44s  \n",
            "\n",
            "2024-11-23 08:45:16 (5.00 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size = 200"
      ],
      "metadata": {
        "id": "AMGx1TJGns72"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating the pretrained embedding matrix from glove with 200 embedding size\n",
        "glove_path = \"glove.6B.200d.txt\"\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(glove_path, 'r', encoding='utf-8') as f:\n",
        "  for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = vector\n",
        "\n",
        "vocab_size = len(en_dict)\n",
        "embedding_matrix = np.random.uniform(-0.1, 0.1, (vocab_size, embedding_size))\n",
        "\n",
        "for word, idx in en_dict.items():\n",
        "  if word in embeddings_index:\n",
        "    embedding_matrix[idx] = embeddings_index[word]"
      ],
      "metadata": {
        "id": "yRpxcFT7oP9a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder LSTM\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers):\n",
        "    super(Encoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = nn.Embedding.from_pretrained(torch.FloatTensor(embedding_matrix), freeze=True) # ppretrained embedding, freeze = true because this should not be changed\n",
        "    self.lstm = nn.LSTM(embedding_size, hidden_size, num_layers)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedding = self.embedding(x)\n",
        "    outputs, (hidden, cell) = self.lstm(embedding)\n",
        "    return hidden, cell"
      ],
      "metadata": {
        "id": "UiX7X0tCiXRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder LSTM with Attention\n",
        "class Decoder(nn.Module):\n",
        "  def __init__(self, input_size, embedding_size, hidden_size, num_layers):\n",
        "    super(Decoder, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.num_layers = num_layers\n",
        "\n",
        "    self.embedding = nn.Embedding(input_size, embedding_size) # embedding matrix, cannot use glove because glove is only for english\n",
        "\n",
        "    self.lstm = nn.LSTM(embedding_size + hidden_size, hidden_size, num_layers) # size is embedding_size + hidden_size due to the attention dimension\n",
        "    self.attention = nn.Linear(hidden_size, hidden_size) # linear function for the attention mechanism\n",
        "    self.fun = nn.Linear(hidden_size, input_size) # linear function for converting the output to the size of the vocabulary\n",
        "\n",
        "  def forward(self, x, hidden, cell):\n",
        "    # x is partial translation till now\n",
        "    x = x.unsqueeze(0)\n",
        "    embedding = self.embedding(x)\n",
        "\n",
        "    context = torch.tanh(self.attention(hidden[-1])) # getting the context by applying the attention mechanism\n",
        "    context = context.unsqueeze(0)\n",
        "\n",
        "    result = torch.cat((embedding, context), dim=2) # concateating the embedding and the context\n",
        "\n",
        "    outputs, (hidden, cell) = self.lstm(result, (hidden, cell))\n",
        "    predictions = self.fun(outputs) # applying linear function to take it to its correct dimension\n",
        "    predictions = predictions.squeeze(0)\n",
        "\n",
        "    return predictions, hidden, cell"
      ],
      "metadata": {
        "id": "Fzzlt1uEF8YX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "num_epochs = 13\n",
        "learning_rate = 0.001\n",
        "batch_size = 50\n",
        "inp_size = len(en_dict)\n",
        "out_size = len(hn_dict)\n",
        "\n",
        "hidden_size = 512\n",
        "num_layers = 2"
      ],
      "metadata": {
        "id": "jla-VgsCVyUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoder = Encoder(inp_size, embedding_size, hidden_size, num_layers).to(device)\n",
        "encoder"
      ],
      "metadata": {
        "id": "f5E8jAgrje8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f536ba96-82b5-4116-d2f1-94d26464ea80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Encoder(\n",
              "  (embedding): Embedding(61101, 200)\n",
              "  (lstm): LSTM(200, 512, num_layers=2)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(out_size, embedding_size, hidden_size, num_layers).to(device)\n",
        "decoder"
      ],
      "metadata": {
        "id": "KlNIo9cEW68M",
        "outputId": "102cd56c-4764-4725-f891-77824e226f48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Decoder(\n",
              "  (embedding): Embedding(74785, 200)\n",
              "  (lstm): LSTM(200, 512, num_layers=2)\n",
              "  (fun): Linear(in_features=512, out_features=74785, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#defining loss criterion and optimizers\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "enc_optimizer = torch.optim.Adam(encoder.parameters(), lr = learning_rate)\n",
        "dec_optimizer = torch.optim.Adam(decoder.parameters(), lr = learning_rate)"
      ],
      "metadata": {
        "id": "EFTpXqv0XapK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#batching the datasets\n",
        "train_x = np.array(en_tokentrain)\n",
        "train_y = np.array(hn_tokentrain)\n",
        "test_x = np.array(en_tokenval)\n",
        "\n",
        "train_ds = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
        "test_ds = TensorDataset(torch.from_numpy(test_x))\n",
        "\n",
        "train_dl = DataLoader(train_ds, shuffle=False, batch_size=batch_size, drop_last=True)\n",
        "test_dl = DataLoader(test_ds, shuffle=False, batch_size=1, drop_last=True)"
      ],
      "metadata": {
        "id": "bZjMmVhHUB90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SOS = en_dict['<SOS>']\n",
        "EOS = en_dict['<EOS>']\n",
        "PAD = en_dict['<PAD>']\n",
        "\n",
        "# Training loop\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  losses = []\n",
        "  for idx, batch in enumerate(train_dl):\n",
        "    input_tensor = batch[0].to(device)\n",
        "    target_tensor = batch[1].to(device) # sending everything to device\n",
        "    target_tensor = target_tensor.transpose(0, 1)\n",
        "    input_tensor = input_tensor.transpose(0, 1) # making the dimensions correct\n",
        "\n",
        "    enc_optimizer.zero_grad()\n",
        "    dec_optimizer.zero_grad() # resetting the gradients\n",
        "\n",
        "    seq_len = target_tensor.shape[0]\n",
        "    outputs = torch.zeros(seq_len, batch_size, out_size).to(device)\n",
        "\n",
        "    hidden, cell = encoder(input_tensor) # callig the encoder to get the initial hidden\n",
        "    last = target_tensor[0] # this is partial translation, initially SOS\n",
        "\n",
        "    for t in range(1, seq_len):\n",
        "      output, hidden, cell = decoder(last, hidden, cell) # using the decoder and getting its output in predicting the next character\n",
        "\n",
        "      best = output.argmax(1) # best is the most likely next character by argmax on dimension\n",
        "      outputs[t] = output\n",
        "      last = target_tensor[t] # teacher forcing so we give it the actual next character\n",
        "\n",
        "    # print(outputs.shape)\n",
        "    # print(target_tensor.shape)\n",
        "    outputs = outputs.reshape(-1, outputs.shape[2])\n",
        "    target_tensor = target_tensor.reshape(-1) # reshaping the dimensions to pass it to loss\n",
        "    # print(outputs.shape)\n",
        "    # print(target_tensor.shape)\n",
        "    loss = criterion(outputs, target_tensor)\n",
        "\n",
        "    loss.backward()\n",
        "    losses.append(loss.item())\n",
        "\n",
        "    torch.nn.utils.clip_grad_norm_(encoder.parameters(), max_norm=1)\n",
        "    torch.nn.utils.clip_grad_norm_(decoder.parameters(), max_norm=1) # clipping the gradients to ensure it doesnt become too large\n",
        "\n",
        "    enc_optimizer.step()\n",
        "    dec_optimizer.step() # updating the tuneable parameters\n",
        "\n",
        "    # print(loss.item())\n",
        "    # if (idx == 5):\n",
        "    #   break\n",
        "\n",
        "    if (idx % 400 == 0):\n",
        "      val = sum(losses) / losses.__len__()\n",
        "      print(f\"DONE, {idx}, {val}\")\n",
        "  print(f\"Epoch {epoch}\" )"
      ],
      "metadata": {
        "id": "a49oQ3BUXcyK",
        "outputId": "c1c31323-5f9b-4f08-b0da-ab116efc938b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DONE, 0, 11.222258567810059\n",
            "DONE, 400, 5.0741376002827785\n",
            "DONE, 800, 4.760934595460451\n",
            "DONE, 1200, 4.580705287752302\n",
            "DONE, 1600, 4.460132755539255\n",
            "Epoch 0\n",
            "DONE, 0, 3.7315168380737305\n",
            "DONE, 400, 3.818614262297861\n",
            "DONE, 800, 3.7386180911022477\n",
            "DONE, 1200, 3.6723610747366724\n",
            "DONE, 1600, 3.626066800134767\n",
            "Epoch 1\n",
            "DONE, 0, 3.259782552719116\n",
            "DONE, 400, 3.299537281740336\n",
            "DONE, 800, 3.2290496046325834\n",
            "DONE, 1200, 3.1747143778773173\n",
            "DONE, 1600, 3.135569767532015\n",
            "Epoch 2\n",
            "DONE, 0, 2.8238754272460938\n",
            "DONE, 400, 2.8794480214392455\n",
            "DONE, 800, 2.8183450874466724\n",
            "DONE, 1200, 2.7708697452036963\n",
            "DONE, 1600, 2.737418176530675\n",
            "Epoch 3\n",
            "DONE, 0, 2.4850897789001465\n",
            "DONE, 400, 2.5368535429462233\n",
            "DONE, 800, 2.488795018969999\n",
            "DONE, 1200, 2.4535987906213803\n",
            "DONE, 1600, 2.4287478272279004\n",
            "Epoch 4\n",
            "DONE, 0, 2.208441734313965\n",
            "DONE, 400, 2.2778837701626253\n",
            "DONE, 800, 2.239657881108116\n",
            "DONE, 1200, 2.2123864021626836\n",
            "DONE, 1600, 2.1926273448552136\n",
            "Epoch 5\n",
            "DONE, 0, 1.9877806901931763\n",
            "DONE, 400, 2.073401280174826\n",
            "DONE, 800, 2.0417250118005588\n",
            "DONE, 1200, 2.0182129359066634\n",
            "DONE, 1600, 2.0019293023525813\n",
            "Epoch 6\n",
            "DONE, 0, 1.8278175592422485\n",
            "DONE, 400, 1.9028371391153693\n",
            "DONE, 800, 1.8763098169057706\n",
            "DONE, 1200, 1.8555658621950808\n",
            "DONE, 1600, 1.841438216689525\n",
            "Epoch 7\n",
            "DONE, 0, 1.6619971990585327\n",
            "DONE, 400, 1.755832089153014\n",
            "DONE, 800, 1.7322876972800931\n",
            "DONE, 1200, 1.7134446171697828\n",
            "DONE, 1600, 1.7004865932881572\n",
            "Epoch 8\n",
            "DONE, 0, 1.5570415258407593\n",
            "DONE, 400, 1.6249906211125287\n",
            "DONE, 800, 1.6048779316460446\n",
            "DONE, 1200, 1.587758678182972\n",
            "DONE, 1600, 1.576282511123786\n",
            "Epoch 9\n",
            "DONE, 0, 1.423537015914917\n",
            "DONE, 400, 1.5066689746338233\n",
            "DONE, 800, 1.49036420909653\n",
            "DONE, 1200, 1.47555354235075\n",
            "DONE, 1600, 1.4663056776271919\n",
            "Epoch 10\n",
            "DONE, 0, 1.318546175956726\n",
            "DONE, 400, 1.4080295767867357\n",
            "DONE, 800, 1.3927010988325959\n",
            "DONE, 1200, 1.3785570514489967\n",
            "DONE, 1600, 1.3705978652672943\n",
            "Epoch 11\n",
            "DONE, 0, 1.22051203250885\n",
            "DONE, 400, 1.3190790560477392\n",
            "DONE, 800, 1.3042590695522847\n",
            "DONE, 1200, 1.2902860761582107\n",
            "DONE, 1600, 1.283266290138097\n",
            "Epoch 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hn_revdict = {v: k for k, v in hn_dict.items()} # reverse dictionary to convert sequences back to hindi sentences"
      ],
      "metadata": {
        "id": "RXJKg9zIfWvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# translating a sentence\n",
        "def translate_tensor(sentence_tensor):\n",
        "  input_tensor = sentence_tensor.to(device)\n",
        "\n",
        "  enc_optimizer.zero_grad()\n",
        "  dec_optimizer.zero_grad()\n",
        "\n",
        "  len = MAX_LEN\n",
        "\n",
        "  hidden, cell = encoder(input_tensor)\n",
        "\n",
        "  out = [SOS]\n",
        "\n",
        "  for t in range(1, len):\n",
        "    last = torch.LongTensor([out[-1]]).to(device)\n",
        "    output, hidden, cell = decoder(last, hidden, cell)\n",
        "    best = output.argmax(1) # this is the most likely token\n",
        "    out.append(best.to('cpu').item())\n",
        "    if (best.item() == EOS): # if predicted end of sentence, break\n",
        "      break\n",
        "\n",
        "    last = best\n",
        "\n",
        "  return out"
      ],
      "metadata": {
        "id": "_3OcyfiCfdkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def translate_lang(sentence_tensor):\n",
        "  translated_tensor = translate_tensor(sentence_tensor)\n",
        "  translated = []\n",
        "  for x in translated_tensor:\n",
        "    if (x == EOS or x == PAD or x == SOS):\n",
        "      continue # ignore special characters\n",
        "\n",
        "    translated.append(hn_revdict[x])\n",
        "\n",
        "  result = \" \".join(translated)\n",
        "  return result"
      ],
      "metadata": {
        "id": "WFcTHNAVffWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, batch in enumerate(test_dl):\n",
        "  # small sample of outputs to check\n",
        "  input_tensor = batch[0].to(device)\n",
        "  input_tensor = input_tensor.transpose(0, 1)\n",
        "\n",
        "  print(translate_lang(input_tensor))\n",
        "  if (idx == 10):\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWPMdWR4fhd4",
        "outputId": "261be1e2-3748-4e4d-9a3c-66d48011cab6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "बस इस पर मेरे साथ एक नया रास्ता मिलेगा ।\n",
            "शराब और अनावश्यक डाइट देना ।\n",
            "जौ में इसकी खेती मुख्यतः सिंचाई के लिए भी जानी जाती है क्योंकि यह भी एक महत्वपूर्ण फसल है और यह भी है कि जस्ता\n",
            "इस चूर्ण के चलते तीन दिन पोस्टइन्क्यूबेशन में से अधिक सोया भोजन को तैयार किया जाता है ।\n",
            "संसार का पौधा संसार का हराभरा एक समुद्री भूमि में फैला हुआ है ।\n",
            "तो यह शीर्ष वर्ग है लेकिन कुछ भी लोकल वेरिएबल में हैं ।\n",
            "कोलोरेक्टल कैंसर फेफड़े स्तन कैंसर हृदय रोग सुन्न व रीढ़ की हड्डी में कैंसर का खतरा बहुत बढ़ जाता है ।\n",
            "तो अगर यहां समाप्त हो तो फिर हमें यहां दो या तीन बार करें ।\n",
            "बस सड़क के माध्यम से घिरा है जो सड़क द्वारा बनाया जाता है ।\n",
            "महाबली को पेश किया गया था और उस स्थान पर उसके नाम के ऊपर पहुँच गए थे और वह इस शहर के नाम पर बनाया\n",
            "यह दुनिया के सबसे पुराने और प्रसिद्ध नृत्य चलचित्र वास्तव में लोक नृत्य के सबसे लोकप्रिय पक्ष में से एक है ।\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(11):\n",
        "  print(en_val[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nvyOK1WfjNX",
        "outputId": "31061b63-9a5d-4b16-c096-d9e7efc7b5fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<SOS>', 'somebody', 'on', 'this', 'side', 'what', 'will', 'be', 'my', 'goaltest', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n",
            "['<SOS>', 'avoid', 'alcohol', 'and', 'illicit', 'drugs', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n",
            "['<SOS>', 'barley', 'is', 'also', 'used', 'for', 'malt', 'production', 'which', 'is', 'principally', 'used', 'in', 'brewing', 'industry', 'and', 'proving', 'itself', 'as', 'a', 'good', 'source', 'of', 'better', 'rural', 'livelihood', '<EOS>']\n",
            "['<SOS>', 'rana', 'daggubati', 'shed', ' ', 'kilograms', 'for', 'this', 'film', 'by', 'eating', 'vegetarian', 'food', 'for', 'six', 'weeks', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n",
            "['<SOS>', 'cradle', 'mountainlake', 'st', 'clair', 'national', 'park', 'a', 'world', 'heritage', 'area', 'is', 'a', 'vast', 'alpine', 'region', 'of', 'wild', 'and', 'stunning', 'beauty', 'with', 'ancient', 'forests', 'and', 'heaths', '<EOS>']\n",
            "['<SOS>', 'so', 'it', 'is', ' ', 'channels', 'but', 'the', 'number', 'of', 'locations', 'is', ' ', 'cross', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n",
            "['<SOS>', 'colorectal', 'cancer', '–', 'bleeding', 'per', 'rectum', 'altered', 'bowel', 'habit', 'lower', 'abdominal', 'pain', 'lump', 'etc', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n",
            "['<SOS>', 'so', 'if', 'we', 'have', 'queen', 'over', 'here', 'and', 'a', 'queen', 'over', 'here', 'then', 'they', 'will', 'capture', 'each', 'other', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n",
            "['<SOS>', 'ortigia', 'has', 'been', 'connected', 'with', 'the', 'rest', 'of', 'the', 'city', 'through', 'a', 'bridge', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<EOS>']\n",
            "['<SOS>', 'lalitaditya', 'was', 'equally', 'a', 'great', 'builder', 'and', 'he', 'built', 'his', 'capital', 'near', 'the', 'sacred', 'shrine', 'of', 'khirbhawani', 'and', 'gave', 'it', 'the', 'name', 'of', 'parihaspur', 'city', '<EOS>']\n",
            "['<SOS>', 'it', 'is', 'one', 'of', 'the', 'busiest', 'art', 'galleries', 'in', 'the', 'world', ' ', 'where', 'from', 'opera', 'to', 'circus', ' ', 'rock', 'and', 'cabaret', 'all', 'kinds', 'of', 'performances', '<EOS>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "val_outs = []\n",
        "# running the model on the whole dataset\n",
        "print(len(test_dl))\n",
        "for idx, batch in enumerate(test_dl):\n",
        "  input_tensor = batch[0].to(device)\n",
        "  input_tensor = input_tensor.transpose(0, 1)\n",
        "\n",
        "  val_outs.append(translate_lang(input_tensor))\n",
        "  if (idx % 1000 == 0):\n",
        "    print(f\"Done, {idx}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt_6ICw4fuY_",
        "outputId": "8a7da2c6-7286-438f-f309-7b853f86eefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11543\n",
            "Done, 0\n",
            "Done, 1000\n",
            "Done, 2000\n",
            "Done, 3000\n",
            "Done, 4000\n",
            "Done, 5000\n",
            "Done, 6000\n",
            "Done, 7000\n",
            "Done, 8000\n",
            "Done, 9000\n",
            "Done, 10000\n",
            "Done, 11000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "id_val = []\n",
        "#finding the id of the validation data\n",
        "with open('/content/drive/MyDrive/Data ML Comp 2/val_data1.json', 'r') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "for lang_pair, lang_data in data.items():\n",
        "  if (lang_pair == \"English-Hindi\"):\n",
        "    for ty, entries in lang_data.items():\n",
        "      print(\"TYPE is \", ty)\n",
        "      if (ty == \"Train\"):\n",
        "        for id, entry_data in entries.items():\n",
        "          pass\n",
        "          # en_train.append(entry_data['source'])\n",
        "          # hn_train.append(entry_data['target'])\n",
        "          # id_train.append(id)\n",
        "      else:\n",
        "        for id, entry_data in entries.items():\n",
        "          # en_val.append(entry_data['source'])\n",
        "          # hn_val.append(entry_data['target'])\n",
        "          id_val.append(id)\n",
        "\n",
        "print(len(id_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxXfMsT2hR5R",
        "outputId": "89bd80bf-5b6a-484c-a5c0-8595aeef221d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TYPE is  Validation\n",
            "11543\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer = pd.DataFrame()\n",
        "answer[\"ID\"] = id_val\n",
        "answer[\"Translation\"] = val_outs"
      ],
      "metadata": {
        "id": "4lYJfIK2hKNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "n6HHMjzgheby",
        "outputId": "d5584961-8311-46bf-b8a7-e396bfc0e972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ID                                        Translation\n",
              "0      505511           बस इस पर मेरे साथ एक नया रास्ता मिलेगा ।\n",
              "1      505512                       शराब और अनावश्यक डाइट देना ।\n",
              "2      505513  जौ में इसकी खेती मुख्यतः सिंचाई के लिए भी जानी...\n",
              "3      505514  इस चूर्ण के चलते तीन दिन पोस्टइन्क्यूबेशन में ...\n",
              "4      505515  संसार का पौधा संसार का हराभरा एक समुद्री भूमि ...\n",
              "...       ...                                                ...\n",
              "11538  517049  भीम अपने पति के साथ उनके पुत्र बने थे और दो दि...\n",
              "11539  517050  यह किस्म ज्यादातर घास के मैदान में लगाई जा सकत...\n",
              "11540  517051  मुझे हरियाणा में आंध्र प्रदेश में सबसे पास का ...\n",
              "11541  517052  में सेंट लुइस की लगभग आधी फुट ऊंचा दर में फैले...\n",
              "11542  517053                मैं एक medium rare steak कैसे बनाऊं\n",
              "\n",
              "[11543 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e5a111bc-a2d5-41a1-a8fb-b521d8c8e1c9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Translation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>505511</td>\n",
              "      <td>बस इस पर मेरे साथ एक नया रास्ता मिलेगा ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>505512</td>\n",
              "      <td>शराब और अनावश्यक डाइट देना ।</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>505513</td>\n",
              "      <td>जौ में इसकी खेती मुख्यतः सिंचाई के लिए भी जानी...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>505514</td>\n",
              "      <td>इस चूर्ण के चलते तीन दिन पोस्टइन्क्यूबेशन में ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>505515</td>\n",
              "      <td>संसार का पौधा संसार का हराभरा एक समुद्री भूमि ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11538</th>\n",
              "      <td>517049</td>\n",
              "      <td>भीम अपने पति के साथ उनके पुत्र बने थे और दो दि...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11539</th>\n",
              "      <td>517050</td>\n",
              "      <td>यह किस्म ज्यादातर घास के मैदान में लगाई जा सकत...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11540</th>\n",
              "      <td>517051</td>\n",
              "      <td>मुझे हरियाणा में आंध्र प्रदेश में सबसे पास का ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11541</th>\n",
              "      <td>517052</td>\n",
              "      <td>में सेंट लुइस की लगभग आधी फुट ऊंचा दर में फैले...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11542</th>\n",
              "      <td>517053</td>\n",
              "      <td>मैं एक medium rare steak कैसे बनाऊं</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11543 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e5a111bc-a2d5-41a1-a8fb-b521d8c8e1c9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e5a111bc-a2d5-41a1-a8fb-b521d8c8e1c9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e5a111bc-a2d5-41a1-a8fb-b521d8c8e1c9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ec0c491d-d871-4920-bd83-2a61796c3e16\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec0c491d-d871-4920-bd83-2a61796c3e16')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ec0c491d-d871-4920-bd83-2a61796c3e16 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_20e7bf3f-11f5-48c4-9dda-88d87a0fee1c\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('answer')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_20e7bf3f-11f5-48c4-9dda-88d87a0fee1c button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('answer');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "answer",
              "summary": "{\n  \"name\": \"answer\",\n  \"rows\": 11543,\n  \"fields\": [\n    {\n      \"column\": \"ID\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11543,\n        \"samples\": [\n          \"514706\",\n          \"511624\",\n          \"506478\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Translation\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 11472,\n        \"samples\": [\n          \"\\u092e\\u094d\\u092f\\u0942\\u0928\\u093f\\u0916 \\u0915\\u0947 \\u092b\\u093e\\u0938\\u0932\\u0947 \\u092a\\u0930 \\u0906\\u0920 \\u0915\\u093f\\u0932\\u094b\\u092e\\u0940\\u091f\\u0930 \\u0932\\u0902\\u092c\\u0940 \\u0938\\u0940\\u095d\\u093f\\u092f\\u093e\\u0901 \\u0939\\u0948 \\u091c\\u094b \\u0915\\u093f \\u0905\\u0902\\u0926\\u0930 \\u0938\\u0947 \\u092c\\u093e\\u0939\\u0930 \\u0915\\u0940 \\u0917\\u0939\\u0930\\u093e\\u0908 \\u092e\\u093f\\u0932\\u0924\\u0940 \\u0939\\u0948 \\u0914\\u0930 \\u092b\\u093f\\u0930 \\u0906\\u092a \\u0915\\u0941\\u091b \\u0914\\u0930 \\u0932\\u094b\\u0917\\u094b\\u0902 \\u0915\\u094b\",\n          \"\\u0915\\u093f\\u0932\\u093e \\u0906\\u0927\\u0941\\u0928\\u093f\\u0915 \\u0938\\u092e\\u092f \\u092e\\u0947\\u0902 \\u092c\\u094d\\u0930\\u093f\\u091f\\u093f\\u0936 \\u0936\\u093e\\u0938\\u0928 \\u0915\\u0947 \\u0926\\u094c\\u0930\\u093e\\u0928 \\u090f\\u0915 \\u0905\\u092b\\u0917\\u093e\\u0928 \\u0938\\u0902\\u0927\\u093f \\u092a\\u094d\\u0930\\u0923\\u093e\\u0932\\u0940 \\u0925\\u0940 \\u091c\\u093f\\u0938\\u0928\\u0947 \\u0905\\u0902\\u0917\\u094d\\u0930\\u0947\\u091c\\u094b\\u0902 \\u0915\\u094b \\u091c\\u0940\\u0924\\u0928\\u0947 \\u0915\\u093e \\u0928\\u093f\\u0930\\u094d\\u0923\\u092f \\u0932\\u093f\\u092f\\u093e \\u0917\\u092f\\u093e \\u0964\",\n          \"\\u092e\\u0941\\u091d\\u0947 \\u0938\\u094d\\u091f\\u0947\\u0936\\u0928 \\u0938\\u0947 \\u0915\\u092e \\u092c\\u091c\\u091f \\u0938\\u0921\\u093c\\u0915\\u094b\\u0902 \\u092a\\u0930 \\u0910\\u0924\\u093f\\u0939\\u093e\\u0938\\u093f\\u0915 \\u092e\\u0939\\u0924\\u094d\\u0935 \\u092a\\u0930 \\u0930\\u0916\\u093e \\u0917\\u092f\\u093e \\u0939\\u0948\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "answer.to_csv(\"/content/drive/MyDrive/answers v1/answersH3.csv\", index=False) # saving answer to file"
      ],
      "metadata": {
        "id": "VjNx9Hqmhl4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = '/content/drive/MyDrive/model_checkpoint_hindi_271.pth' # saving the model to a file to reuse\n",
        "\n",
        "torch.save({\n",
        "    'encoder_state_dict': encoder.state_dict(),\n",
        "    'decoder_state_dict': decoder.state_dict(),\n",
        "    'enc_optimizer_state_dict': enc_optimizer.state_dict(),\n",
        "    'dec_optimizer_state_dict': dec_optimizer.state_dict(),\n",
        "}, checkpoint_path)"
      ],
      "metadata": {
        "id": "en483E4whote"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}